---
title: "Basic Statistics"
subtitle: "BODL R Training"
author: "Dr Stevie Pederson"
institute: "Black Ochre Data Labs<br>Telethon Kids Institute"
date: "2023-02-17"
date-format: long
title-slide-attributes:
    data-background-color: "#3c3c44"
    data-background-image: assets/bodl_logo_white_background.jpg
    data-background-opacity: "0.3"
    data-background-size: "90%"
editor: source
format: 
  revealjs:
    theme: [../custom.scss]
    code-line-numbers: false
    width: 1024
    height: 768
    sansfont: Times New Roman
    logo: assets/bodl_logo_white_background.jpg
---

```{r setup, echo = FALSE, include = FALSE}
if (interactive()) setwd(here::here("docs"))
knitr::opts_chunk$set(
  echo = TRUE, include = TRUE, warning = FALSE, message = FALSE, 
  fig.align = "center", results = 'hide', fig.show = "asis",
  fig.width = 6,
  collapse=TRUE
)
```

# Basic Statistical Techniques {background-color="#3c3c44"}

## Introduction

- `R` has it's origins as a statistical analysis language (i.e. `S`)
- Purpose of this session is NOT to teach statistics
- I am a Bioinformatician NOT statistician
- How do we perform simple analyses in R?
    - Up to you to know what you're doing
    - Or **talk to your usual statistician**

## Distributions

- `R` comes with nearly every distribution
- Standard syntax for accessing each

## Distributions 

| Distribution | Density   | Area Under Curve | Quantile  | Random    |
|:------------ |:--------- |:---------------- |:--------- |:--------- |
| Normal       | `dnorm()` | `pnorm()`        | `qnorm()` | `rnorm()` |
| T            | `dt()`    | `pt()`           | `qt()`    | `rt()`    |
| Uniform      | `dunif()` | `punif()`        | `qunif()` | `runif()` |
| Exponential  | `dexp()`  | `pexp()`         | `qexp()`  | `rexp()`  |
| $\chi^2$     | `dchisq()` | `pchisq()`      | `qchisq()` | `rchisq()` |
| Binomial     | `dbinom()` | `pbinom()`      | `qbinom()` | `rbinom()` |
<!-- | Poisson      | `dpois()` | `ppois()`        | `qpois()` | `rpois()` | -->

## Distributions 

- Also Poisson, Beta, $\Gamma$, Log-Normal, F, Geometric, Cauchy, Hyper-geometric etc...

```{r dist-help, eval=FALSE}
?Distributions
```


## Distributions

Take a random sample from a few important distributions

```{r randomSamples}
library(tidyverse)
randomSamples <- list(
  Normal = rnorm(1000, mean = 1, sd = 1),
  Uniform = runif(1000, min = -0.732, max = 2.732),
  Exponential = rexp(1000, rate = 1),
  Poisson = rpois(1000, lambda = 1)
)
```

These were all sampled from distributions with $\mu = 1$; $\sigma = 1$

## Distributions {.smaller}

- Normal
    + The most common distribution (i.e. Bell Curve)
    + Most statistical theory developed for this type of data
    
. . .

- Uniform
    + Can appear anywhere within a range, with equal probability
    + Most common example: $p$-values under $H_0$

. . .

- Exponential
    + Continuous data
    + Common example is the time between events occurring

. . .

- Poisson
    + Discrete (i.e. count) data
    + Number of phone calls per minute
    + Number of alignments per kb

## Distributions 

**Why are the sample means & std. deviations not exactly equal to 1?**

```{r means_pander, echo=FALSE, include=TRUE, results='asis'}
library(pander)
randomSamples %>% 
  lapply(function(x) tibble(mn = mean(x), sd = sd(x))) %>% 
  bind_rows(.id = "Distribution") %>% 
  pander(
    justify = "lrr",
    col.names = c("Distribution", "$\\hat{\\mu}$", "$\\hat{\\sigma}$")
  )
```


## All Densities

```{r plot-dist, echo=FALSE, fig.show='asis', fig.align='center', fig.width=8, fig.height=6}
theme_set(theme_bw())
randomSamples %>%
  lapply(as_tibble_col) %>% 
  bind_rows(.id = "Distribution") %>% 
  ggplot(aes(x = value, fill = Distribution)) +
  geom_histogram(colour = "grey50", alpha = 0.7, bins = 50) +
  geom_vline(xintercept = 1, linetype = 2, colour = "blue") +
  facet_wrap(~Distribution, ncol = 2, scales = "free")  +
  theme(text = element_text(size = 14))
```

## All Densities

```{r boxplot-dist, echo=FALSE, fig.show='asis', fig.width=8, fig.height=6, fig.align='center'}
randomSamples %>%
  lapply(as_tibble_col) %>% 
  bind_rows(.id = "Distribution") %>% 
  ggplot(aes(x = Distribution, y = value, fill = Distribution)) +
  geom_boxplot(colour = "grey50", alpha = 0.7) +
  geom_hline(yintercept = 1, linetype = 2, colour = "blue") +
  theme(text = element_text(size = 14))
```

# Basic Tests  {background-color="#3c3c44"}

## Data For This Session

We'll use the `toothData` dataset we saw yesterday

- Length of teeth in rats
- Two vitamin C supplementation methods
- Three dose levels

```{r, results='hide'}
toothData <- read_csv("data/toothData.csv") %>%
  mutate(
    dose = fct(dose, levels = c("Low", "Med", "High")),
    supp = as_factor(supp)
  )
glimpse(toothData)
```

## Data For This Session

```{r boxplot-teeth, fig.width=8, fig.height=6, fig.align='center'}
#| output-location: column
ggplot(
  toothData, 
  aes(x = dose, y = len, fill = supp)) +
  geom_boxplot() +
  theme_bw() +
  theme(text = element_text(size = 16))
```


## t-tests

- Data should be normally distributed
- $t$-tests always test $H_0$ Vs $H_A$
    - (We may not always do meaningful tests today)

## t-tests

- The simplest test is on a simple vector
    + The below is a bit of a dumb test
    + Demonstrates the code (not the statistics)

```{r}
?t.test
t.test(toothData$len)
```

**What is $H_0$ in the above test?**

. . .

$$
H_0: \mu = 0\\
H_A: \mu \neq 0
$$

## t-tests

$$
H_0: \mu_{1} = \mu_{2} \\
H_A: \mu_{1} \neq \mu_{2}
$$

We could use two vectors (i.e. `x` & `y`)

```{r}
x <- toothData$len[toothData$supp == "VC"]
y <- toothData$len[toothData$supp == "OJ"]
t.test(x, y)
```

**Is this a paired test?**

## t-tests

$$
H_0: \mu_{1} = \mu_{2} \\
H_A: \mu_{1} \neq \mu_{2}
$$

Or we could use the `R` formula method:

`len~supp`: *len* (the response) is dependent on *supp* (the predictor)

```{r}
t.test(len~supp, data = toothData)
```

**Did this give the same results?**

## Working With Objects of Class `htest()`

- The results of `t.test()` are of class `htest`

```{r ttest-res, results='hide'}
res <- t.test(len~supp, data = toothData)
class(res)
typeof(res)
glimpse(res)
```

. . .

```{r print-res, results='markup'}
#| output-location: default
res
```

- When we type the object name: `print()` is called
- `print()` actually looks for a function `print.htest()`
- This is known as an `S3` method
    + More on these later

## Working With Objects of Class `htest()`

- We know these objects are just a list
    + Can grab any values we want
    
```{r res-details, results='markup'}
names(res)
res$statistic
res$parameter
res$p.value
res$conf.int
```

. . .

- We can place these inline using \``r`\`

## Working With Objects of Class `htest()`

- `pander` is excellent for formatting the complete results 

```{r pander-res, results='asis'}
pander(res, split.table = Inf)
```

## Working With Objects of Class `htest()`

- `tidy()` from the package `broom` will produced a `tibble()`

```{r results='markup'}
library(broom)
tidy(res)
```


## Wilcoxon Tests  

- We assumed the data was normally distributed: **What if it's not?**
- Non-parametric alternative is the *Wilcoxon Rank-Sum* (aka *Mann-Whitney*)

$$
H_0: \text{Distribution}_1 = \text{Distribution}_2 \\
H_A: \text{Distribution}_1 \neq \text{Distribution}_2
$$

## Wilcoxon Tests 

- This assigns *ranks* to each value based on their value
    - Tied values can be problematic
    + Test is based on *ranks* not values
- Still produces an object f class `htest`

```{r wilcox-test, results='markup'}
#| output-location: fragment
res <- wilcox.test(len~supp, data = toothData)
class(res)
names(res)
res
```


## $\chi^2$ Test

- Here we need counts
- Often a $2 \times 2$ table
- Commonly used in *Observed Vs Expected*

$$
H_0: \text{No dependence between groups and outcome}\\
H_A: \text{Dependence between groups and outcome}
$$


## $\chi^2$ Test

```{r, results='markup'}
pass <- matrix(c(25, 8, 6, 15), nrow = 2)
colnames(pass) <- c("Pass", "Fail")
rownames(pass) <- c("Attended", "Skipped")
pass
```

. . .

```{r, results='markup'}
res <- chisq.test(pass)
names(res)
class(res)
res
```

. . .

**Can anyone remember when we shouldn't use a $\chi^2$ test?**

## Fisher's Exact Test

- $\chi^2$ tests became popular in the days of the printed tables
    - We now have computers
- Fisher's Exact Test is preferable in the cases of low cell counts
    - Uses the hypergeometric distribution
- Same $H_0$ as the $\chi^2$ test

```{r, results = 'markup'}
fTest <- fisher.test(pass)
names(fTest)
class(fTest)
fTest
```

## Basic Hypothesis Testing

1. $t$-tests
2. Wilcoxon Rank-Sum tests (aka Mann-Whitney)
3. $\chi^2$ tests
4. Fisher's Exact Test

## Basic Hypothesis Testing

All tests gave similar looking output.

- Objects of class `htest`
    - Print & markdown formatting methods exist for this class
    - `tibble` coercion also exists
- These are list objects
    + We can simply grab any values we need


# Regression {background-color="#3c3c44"}

## Linear Regression

Recap: We are trying to estimate a line

$$
y = ax + b
$$

Or 

$$
y = \beta_0 + \beta_1 x
$$


## Linear Regression

Linear Regression always uses the `R` formula syntax

- `y ~ x` means `y` depends on `x`
    + i.e. $y = \beta_0 + \beta_1x$
    + The Intercept term is assumed unless explicitly removed (`~ 0 + ...`)
- We use the function `lm()`

```{r}
lm_tooth <- lm(len ~ supp , data = toothData) 
```

## Linear Regression

```{r}
lm_tooth <- lm(len ~ supp , data = toothData) 
```


- Produces an `list` object of class `lm`
- `print.lm` methods exist
    + Not quite as helpful as for `htest`
    
. . .

```{r, results='hide'}
names(lm_tooth)
glimpse(lm_tooth)
lm_tooth
```

## Linear Regression

- `pander` also works nicely

```{r, results='asis'}
pander(lm_tooth)
```

## Linear Regression

- `pander()` actually calls `summary()` before printing
    + This produces the main output table we look for
    
```{r, results='markup'}
summary(lm_tooth)
```

## Linear Regression

- We can also run a simple ANOVA

```{r, results='markup'}
anova(lm_tooth)
```

## Linear Regression

- Both `anova()` and `summary()` also create objects
    + `anova()` creates a `data.frame`
    + `summary()` creates a `list`

```{r, results='hide'}
anova_tooth <- anova(lm_tooth)
class(anova_tooth)
summary_lm_tooth <- summary(lm_tooth)
class(summary_lm_tooth)
typeof(summary_lm_tooth)
glimpse(summary_lm_tooth)
```

. . .

- Again we can extract or create tables as needed

```{r, results='hide'}
summary_lm_tooth$coefficients
```


## Linear Regression

- `broom::tidy()` also works on all objects
    + Calls `summary()` on the basic `lm` object

```{r}
tidy(anova_tooth)
tidy(lm_tooth)
tidy(summary_lm_tooth)
```

## Regression Diagnostics

- Passing an object of class `lm` to `plot()` produces 4 diagnostic plots
    + The are produced in series
- Can be produced in one call by setting the plot device to be two rows and two columns
   + `par()` is used to set global plotting parameters
   + `mfrow` is for Multi-Frame Row-wise plots

```{r lm-diagnostics, fig.show='hide'}
par(mfrow = c(2, 2))
plot(lm_tooth)
par(mfrow = c(1, 1))
```

## Regression Diagnostics

- Can be produced manually using `ggplot`
    + Only needed if specifically required

```{r plot-qq, fig.show='asis'}
#| output-location: column
tibble(
  fitted = fitted(lm_tooth),
  resid = resid(lm_tooth),
  standard = rstandard(lm_tooth)
) %>% 
  ggplot(aes(sample = standard)) +
  stat_qq(shape = 21) +
  stat_qq_line(linetype = 3) +
  ggtitle("Normal Q-Q") +
  labs(
    x = "Theoretical Quantiles",
    y = "Standardized Residuals"
  ) +
  scale_y_continuous(
    expand = expansion(c(0, 0))
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```
  



## Interaction Terms 

- The previous model assumed that tooth length increased by 3.7 across all dose levels
- Do we believe that?

```{r re-boxplot-teeth, ref.label='boxplot-teeth', fig.show='asis'}
#| output-location: column
```

## Interaction Terms

- Adding `dose` to the model would define a new baseline (Intercept) for each dose level
    + `lm ~ dose + supp`
    + The difference is still assumed constant

```{r, results='asis'}
#| output-location: fragment
lm_dose <- lm(len ~ dose + supp, data = toothData) 
pander(lm_dose)
```


## Interaction Terms

- Including an interaction term allows for a different effect at each level

```{r, results='asis'}
#| output-location: fragment
lm_interaction <- lm(len ~ dose + supp + dose:supp, data = toothData) 
pander(lm_interacton)
```


## Interaction Terms

- The complete manual specification was `len ~ dose + supp + dose:supp`
- A shorthand is `len ~ dose * supp`
- When dealing with multiple terms `len ~ (dose + supp)^2`
    + The exponent sets the level of interactions
    
. . .

- Interaction terms usually require careful thought...
    + 3-level interactions get really confusing

## Model Selection

**Which model should we choose?**

- Running an ANOVA on multiple *related* models compares the reduction in the residual Sum of Squares

```{r}
anova(lm_tooth, lm_dose, lm_interaction)
```

. . .

- The p-value tests H~0~: No improvement in model fit when removing the next term
    + Clearly the interaction term improves the fit and should remain
    + This makes intuitive sense

## Other Types of Regression

- `lm` fits conventional linear regression, i.e. Normal Residuals
    + Also assumes all effects are fixed effects
    
. . .

- Mixed effects models are best fit using `lme4::lmer()`
    + Can be clunky syntax, random effects specified using `(1|variable)`
    + No $p$-values provided $\implies$ `lmerTest`
    
. . .

- Poisson and Logistic Regression can be fit using `glm()`
    + Logistic: `glm(..., family = binomial())`
    + Poisson: `glm(..., family = poisson())`

. . .

- Robust Regression using `MASS::rlm()`


# Other Statistical Tools

## Mutiple Testing in R

The function `p.adjust()` takes the argument `method = ...`

- We can select from `c("fdr", "BH", "BY", "holm", "bonferroni")`

Also the package `multcomp` is excellent

## PCA

- Here we have 50 genes:
    + Two T cell types (Th and Treg)
    + Two treatments: Stimulated (+) & Resting (-)
- `PCA` needs a matrix, so I'll transform as I load

```{r}
genes <- read_csv("data/geneExpression.csv") %>%
  as.data.frame() %>% 
  column_to_rownames("ID") %>%
  as.matrix() 
dim(genes)
```

## PCA

- Our variable of interest here is the cell-types (columns)
- We need to set that as the row variable:
- Transpose the data using `t()`
- Run `PCA` using `prcomp()`

```{r generic-pca}
#| output-location: column
pcaGenes <- genes %>% 
  t() %>% 
  prcomp()
summary(pcaGenes)
biplot(pcaGenes)
```

## PCA

- I don't find the standard functions very friendly
- `broom::tidy()` is far more convenient

```{r}
pca_df <- tidy(pcaGenes)
pca_df
```

. . .

- We still might like sample-level information

```{r}
pca_df <- tidy(pcaGenes) %>% 
  mutate(
    cell_type = str_extract(row, "(Th|Treg)") %>% 
      as_factor(),
    treat = case_when(
      str_detect(row, "\\+") ~ "Stim",
      str_detect(row, "\\-") ~ "Resting"
    ) %>% 
      fct(levels = c("Resting", "Stim")),
    group = fct_cross(cell_type, treat, sep = " - ")
  ) 
```


## PCA

- Now we can plot more easily

```{r plot-pca, fig.show='asis'}
#| output-location: column
library(ggrepel)
pca_df %>% 
  dplyr::filter(PC %in% 1:2) %>% 
  pivot_wider(
    names_from = "PC", 
    values_from = "value", 
    names_prefix = "PC"
  ) %>% 
  ggplot(aes(PC1, PC2, colour = treat)) +
  geom_point(
    aes(shape = cell_type), size = 3
  ) +
  geom_label_repel(
    aes(label = row), show.legend = FALSE
  ) +
  scale_colour_manual(
    values = hcl.colors(2, "Zissou1")
  ) +
  scale_shape_manual(values = c(21, 19)) +
  labs(shape = "Cell Type", colour = "Treatment")
```

## PCA

- Alternatively

```{r plot-pca2, fig.show='asis'}
#| output-location: column
library(ggrepel)
pca_df %>% 
  dplyr::filter(PC %in% 1:2) %>% 
  pivot_wider(
    names_from = "PC", 
    values_from = "value", 
    names_prefix = "PC"
  ) %>% 
  ggplot(aes(PC1, PC2, colour = group)) +
  geom_point(
    aes(shape = group), size = 3
  ) +
  scale_colour_manual(
    values = rep(hcl.colors(2, "Zissou1"), 2)
  ) +
  scale_shape_manual(values = c(21, 21, 19, 19)) +
  labs(shape = "Group", colour = "Group") +
  theme(
    legend.position = c(0.99, 0.01),
    legend.justification =  c(1, 0)
  )
```

## Multiple Panels

::: {.panel-tabset}

### PC1 vs PC2

```{r}
C <- pca_df %>% 
  dplyr::filter(PC %in% 1:2) %>% 
  pivot_wider(
    names_from = "PC", 
    values_from = "value", 
    names_prefix = "PC"
  ) %>% 
  ggplot(aes(PC1, PC2, colour = group)) +
  geom_point(
    aes(shape = group), size = 3
  ) +
  scale_colour_manual(
    values = rep(hcl.colors(2, "Zissou1"), 2)
  ) +
  scale_shape_manual(values = c(21, 21, 19, 19)) +
  labs(shape = "Group", colour = "Group") 
```

### PC1 Vs PC3

```{r}
A <- pca_df %>% 
  dplyr::filter(PC %in% c(1, 3)) %>% 
  pivot_wider(
    names_from = "PC", 
    values_from = "value", 
    names_prefix = "PC"
  ) %>% 
  ggplot(aes(PC1, PC3, colour = group)) +
  geom_point(
    aes(shape = group), size = 3
  ) +
  scale_colour_manual(
    values = rep(hcl.colors(2, "Zissou1"), 2)
  ) +
  scale_shape_manual(values = c(21, 21, 19, 19)) +
  labs(shape = "Group", colour = "Group") 
```

### PC2 Vs PC3

```{r}
B <- pca_df %>% 
  dplyr::filter(PC %in% c(2, 3)) %>% 
  pivot_wider(
    names_from = "PC", 
    values_from = "value", 
    names_prefix = "PC"
  ) %>% 
  ggplot(aes(PC2, PC3, colour = group)) +
  geom_point(
    aes(shape = group), size = 3
  ) +
  scale_colour_manual(
    values = rep(hcl.colors(2, "Zissou1"), 2)
  ) +
  scale_shape_manual(values = c(21, 21, 19, 19)) +
  labs(shape = "Group", colour = "Group") 
```

### Cumulative Variance

```{r}
library(scales)
D <- pcaGenes %>% 
  summary() %>% 
  .[["importance"]] %>% 
  as_tibble(rownames = "Type") %>% 
  pivot_longer(cols = starts_with("PC"), names_to = "PC") %>% 
  dplyr::filter(str_detect(Type, "^Proportion")) %>% 
  mutate(PC = fct_inorder(PC) %>% fct_relabel(str_remove, "PC")) %>% 
  ggplot(aes(PC, value)) +
  geom_col(fill = "grey", colour = "black") +
  scale_y_continuous(expand = expansion(c(0, 0.05)), labels = percent) +
  labs(x = "Principal Component", y = "% Variance")
```

:::

## Combined PCA Plot

```{r plot-full-pca, fig.width=9, fig.height=6}
library(patchwork)
(A + B) / (C + D) +
  plot_layout(guides = "collect") + 
  plot_annotation(tag_levels = "A")
```



